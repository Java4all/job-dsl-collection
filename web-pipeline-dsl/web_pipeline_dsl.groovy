//#######################################DOCKER IMAGE INFRASTRUCTURE#######################################
def currentDockerImages = ['linkchecker', 'gh-pages', 'pac', 'image-size-checker', 'geb']

//Convention: all our docker image repos are prefixed with "docker-"
def githubUrl = 'https://github.com/Praqma/docker-'
def branchName = "master" //"\${BRANCH}"
def releasePraqmaCredentials = '100247a2-70f4-4a4e-a9f6-266d139da9db'
def dockerHostLabel = 'dockerhost1'

currentDockerImages.each { image ->
  def cloneUrl = "${githubUrl}"+"${image}"

  //Verification job bame
  def verifyName = "Web_Docker_"+"${image}"+"-verify"

  //Publish job name
  def publishName = "Web_Docker_"+"${image}"+"-publish"

  //Docker repo name
  def dRepoName = "praqma/${image}"

  job(verifyName) {
	label(dockerHostLabel)
	logRotator(-1,10)
    wrappers {
      timestamps()
    }

    triggers {
      githubPush()
    }

    scm {
      git {

        remote {
          url(cloneUrl)
          credentials(releasePraqmaCredentials)
        }

        branch(branchName)

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell("docker build -t praqma/${image}:snapshot .")
      shell('./test.sh')
	   shell("docker rmi praqma/${image}:snapshot")
    }

    publishers {
      buildPipelineTrigger(publishName) {
        parameters{
          gitRevision(false)
        }
      }
	  mailer('', false, false)
    }
  }

  //Publish jobs
  job(publishName) {
    label(dockerHostLabel)
	logRotator(-1,10)
    wrappers {
      timestamps()
    }
    scm {
      git {

        remote {
          url(cloneUrl)
          credentials(releasePraqmaCredentials)
        }

        branch(branchName)
          configure {
            node ->
            node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
          }
        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.UserIdentity' {
            name("praqma");
            email("support@praqma.net");
          }
        }
      }
    }

    steps {
      dockerBuildAndPublish {
        repositoryName(dRepoName)
        tag('1.${BUILD_NUMBER}')
        registryCredentials('docker-hub-crendential')
        dockerHostURI('unix:///var/run/docker.sock')
        forcePull(false)
        createFingerprints(false)
        skipDecorate()
      }
    }

    publishers {
      git {
        pushOnlyIfSuccess()
        branch('origin', branchName)
        tag('origin', '1.${BUILD_NUMBER}') {
          message('Tagged with 1.${BUILD_NUMBER} using Jenkins')
          create()
        }
      }
      mailer('', false, false)
    }

  }
}
//#########################################################################################################

//##########################################WEBSITE CONFIGURATION##########################################
def readyBranch = 'origin/ready/**'
def udate = new Date()

def descriptionHtml = """
<h3>Auto generated by JobDSL plugin</h3>
<p>Updated ${udate}</p>
"""



//List of websites we need to create a pipeline for
def websites = [
  'http://www.josra.org':'https://github.com/josra/josra.github.io.git',
  'http://www.code-conf.com':'https://github.com/Praqma/code-conf.com.git',
  'http://www.lakruzz.com':'https://github.com/lakruzz/lakruzz.github.io.git',
  'http://code-maturity.praqma.com':'https://github.com/Praqma/code-maturity.git'

]

//Specify the full integration branch name
def integrationBranches = [
  'http://www.josra.org':'master',
  'http://www.code-conf.com':'gh-pages',
  'http://www.lakruzz.com':'master',
  'http://code-maturity.praqma.com':'gh-pages'
]

//The 'verify' job is the one that has to pass the tollgate criteria. For websites this is: jekyll build
//We're enabling pretested integration for this part of the pipeline.
//TODO: Currently i have an issue with the docker image not picking up the correct locale when the slave is connected using ssh.
//Ideally this should just spawn a slave just like the rest of the jobs. Instead it just uses do
websites.each { site, weburl ->
  job('Web_'+site.split('http://')[1] + '-verify') {
    label(dockerHostLabel)
	logRotator(-1,10)

 	triggers {
        githubPush()
    }
    wrappers {
      timestamps()
    }

    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(readyBranch)

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell('''
git log \\
    --decorate \\
    --oneline \\
    --graph \\
    ''' + integrationBranches[site] + '''..${GIT_BRANCH} \\
    2>&1 | tee git_graph.txt

GIT_AUTHOR_COMMITTER=`git log --pretty=format:"%ae" -1`

env | grep -e '^GIT' > git.env
''')
      environmentVariables {
        propertiesFile('git.env')
      }
      shell("""
docker run \\
       -u jenkins \\
       --rm \\
       -v \$(pwd):/home/jenkins \\
       praqma/gh-pages \\
       jekyll build 2>&1 | tee jekyll_build.txt
""")
    }

    wrappers {
      pretestedIntegration("SQUASHED", integrationBranches[site], "origin")
      timestamps()
    }

    publishers {
      archiveArtifacts('_site/**')
      textFinder(/ Error: |Warning: |Liquid Exception: /, ''  , true, false, true )
      pretestedIntegration()
      extendedEmail {
        triggers {
          failure {
            attachBuildLog(true)
            attachmentPatterns('*.txt')
            recipientList('${GIT_AUTHOR_COMMITTER}')
          }
          unstable {
            attachBuildLog(true)
            attachmentPatterns('*.txt')
            recipientList('${GIT_AUTHOR_COMMITTER}')
          }
        }
      }
    }
  }

  job('Web_'+site.split('http://')[1] + '-image-size-checker') {
    label(dockerHostLabel)
	logRotator(-1,10)
    description(descriptionHtml)
    wrappers {
      timestamps()
    }

    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(integrationBranches[site])

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell("""
docker run -u jenkins --rm -v \$(pwd):/home/jenkins/site/ praqma/image-size-checker groovy /home/jenkins/imageSizeChecker.groovy
      """)
    }

    publishers {
      textFinder(/Error:/, ''  , true, false, true )
    }
  }

  job('Web_'+site.split('http://')[1] + '-geb') {
    label(dockerHostLabel)
    description(descriptionHtml)

    wrappers {
      timestamps()
    }
    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(integrationBranches[site])

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell("""
docker run -u jenkins --rm -v \${WORKSPACE}:/home/jenkins/site/ praqma/geb /home/jenkins/run.sh
      """)
    }

    publishers {
      textFinder(/Assertion failed:/, ''  , true, false, true )
    }
  }

  //TRIGGER JOBS
  job('Web_'+site.split('http://')[1] + '-trigger') {
	logRotator(-1,10)
    wrappers {
      timestamps()
    }
    triggers {
      githubPush()
    }


    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(integrationBranches[site])

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell('''#!/usr/bin/env bash -x
git branch -a

export GIT_STABLE_BRANCH=$(git branch -a | grep -q -e "remotes/origin/stable$" && echo stable )

if [ "${GIT_STABLE_BRANCH}x" == "x" ] ; then
  export GIT_STABLE_BRANCH=''' + integrationBranches[site] + '''
fi

git log \\
   --decorate \\
   --oneline \\
   --graph \\
   --all \\
   -20 \\
   2>&1 | tee git_graph.txt

_GIT_AUTHOR_COMMITTER=`git log --pretty=format:"%ae" origin/${GIT_STABLE_BRANCH}..HEAD `
if [ "${_GIT_AUTHOR_COMMITTER}x" == "x" ] && [ "${GIT_PREVIOUS_SUCCESSFUL_COMMIT}x" != "${GIT_COMMIT}x" ]; then
  _GIT_AUTHOR_COMMITTER=`git log --pretty=format:"%ae" origin/${GIT_PREVIOUS_SUCCESSFUL_COMMIT}..HEAD`
fi
if [ "${_GIT_AUTHOR_COMMITTER}x" == "x" ]; then
  _GIT_AUTHOR_COMMITTER=`git log --pretty=format:"%ae" -1`
fi

export GIT_AUTHOR_COMMITTER=`echo "${_GIT_AUTHOR_COMMITTER}" | sed -e 's/ /,/g'`

env | grep -e '^GIT' > git.env

cat git.env
''')
      environmentVariables {
        propertiesFile('git.env')
      }
      downstreamParameterized {
        trigger(['Web_'+site.split('http://')[1] + '-linkcheck',
                 'Web_'+site.split('http://')[1] + '-resource-analysis']) {
          block {
            buildStepFailure('FAILURE')
            failure('FAILURE')
            unstable('UNSTABLE')
          }
          parameters{
            gitRevision(true)
          }
        }
      }
      downstreamParameterized {
        trigger(['Web_'+site.split('http://')[1] + '-image-size-checker' ] ) {
          block {
            buildStepFailure('never')
            failure('never')
            unstable('never')
          }
          parameters{
            gitRevision(true)
          }
        }
      }
    }
    publishers {
      git {
        pushOnlyIfSuccess()
        branch('origin', '${GIT_STABLE_BRANCH}')
      }
      archiveArtifacts('git.env','git_graph.txt')
      extendedEmail {
        triggers {
          failure {
            attachBuildLog(true)
            attachmentPatterns('git_graph.txt')
            recipientList('${GIT_AUTHOR_COMMITTER}')
          }
          unstable {
            attachBuildLog(true)
            attachmentPatterns('git_graph.txt')
            recipientList('${GIT_AUTHOR_COMMITTER}')
          }
        }
      }

    }
  }

  //The linkchecker job should run the linkchecker command and produce a set of parsable report files
  job('Web_'+site.split('http://')[1] + '-linkcheck') {
    label('linkchecker')
	logRotator(-1,10)
    description(descriptionHtml)
    wrappers {
      timestamps()
    }

    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(integrationBranches[site])

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell("""
#!/usr/bin/env bash -x

run_linkchecker () {
  linkchecker \\
     \$(test -e linkchecker_ignore_urls.txt && grep '^--ignore-url' linkchecker_ignore_urls.txt) \\
     --user-agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:21.0) Gecko/20100101 Firefox/21.0' \\
     -o text -Fcsv/linkchecker.report.csv \\
     -Fhtml/linkchecker.report.html \\
     --complete \\
     ${site} \\
     > linkchecker.log 2>&1 \\
     || echo 'INFO: Warnings and/or errors detected - needs interpretation'
}

run_linkchecker
grep "timeout: timed out" linkchecker.report.csv && ( echo "We have timeout - try again in 10 sec" && sleep 10 && run_linkchecker )

grep "found. 0 errors found." linkchecker.log || ( cat linkchecker.log  && echo "ERROR: linkchecker issue(s) detected" )

""")
    }

    publishers {
      warnings(null,['LinkChecker CSV (Jekyll flavor)':'linkchecker.report.csv'])

      analysisCollector() {
        warnings()
      }

      publishHtml {
        report('.') {
          reportName('Linkchecker report')
          reportFiles('linkchecker.report.html')
          alwaysLinkToLastBuild(true)
        }
      }
      archiveArtifacts('linkchecker*.*')

      textFinder(/ERROR: linkchecker issue\(s\) detected/, ''  , true, false, true )

      mailer('', false, false)

    }
  }
  //The resource analysis job. TODO: Implement this
  job('Web_'+site.split('http://')[1] + '-resource-analysis') {
	label('ruby')
	logRotator(-1,10)
    wrappers {
      timestamps()
    }
    scm {
      git {

        remote {
          url(weburl)
          credentials(releasePraqmaCredentials)
        }

        branch(integrationBranches[site])

        configure {
          node ->
          node / 'extensions' << 'hudson.plugins.git.extensions.impl.CleanBeforeCheckout' {}
        }
      }
    }

    steps {
      shell('''
ruby /opt/static-analysis/analyzer.rb -c /opt/static-analysis/report_duplication_junit_template.xml -u /opt/static-analysis/report_usage_analysis_junit_template.xml

echo "Unused files:"
grep '<failure type="Unusued file">' report_analysis_unused.xml || echo "INFO: no unused files"

''')
    }
    publishers {
	  archiveXUnit {
	    jUnit {
		  pattern('report_*.xml')
		  failIfNotNew(false)
	    }
        failedThresholds {
          unstableNew(0)
          unstable()
          failure()
          failureNew()
        }
        skippedThresholds{
            unstableNew(0)
            unstable(0)
            failure()
            failureNew()
        }
	  }

      archiveArtifacts('report_*.xml')

	  mailer('', false, false)
    }
  }
}

//#########################################################################################################
